{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"머신러닝을 통한 접근 가이드\" 목차\n",
    "## 1. Library\n",
    "## 2. Data Loading\n",
    "## 3. Feature Engineering\n",
    "### 3-1. Feature Generation\n",
    "#### CODE SHARE WITH \"파베르\"님 \n",
    "#### (https://dacon.io/competitions/official/235745/codeshare/2851?page=1&dtype=recent)\n",
    "### 3-2. Feature Engineering\n",
    "#### 3-2-1. Encoding\n",
    "#### 3-2-2. Scailing\n",
    "## 4. Modeling with Pycaret\n",
    "## 5. Modeling with CatBoostRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for \"2. Data Loading\"\n",
    "import pandas as pd\n",
    "\n",
    "# for \"3-1. Feature Generation\"\n",
    "import numpy as np\n",
    "\n",
    "# for \"3-2. Feature Engineering\"\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
    "\n",
    "# for \"4. Modeling with Pycaret\"\n",
    "from pycaret.regression import *\n",
    "\n",
    "# for \"5. Modeling with CatBoostRegressor\"\n",
    "from catboost import CatBoostRegressor\n",
    "import optuna\n",
    "from optuna import Trial\n",
    "from optuna.samplers import TPESampler\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train0723(5).3.csv')\n",
    "test = pd.read_csv('data/test0723.fi.csv')\n",
    "train = train.set_index(\"code\")\n",
    "test = test.set_index(\"code\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-1. Feature Generation\n",
    "#### CODE SHARE WITH \"파베르\"님 \n",
    "#### (https://dacon.io/competitions/official/235745/codeshare/2851?page=1&dtype=recent)\n",
    "##### Feature Generation과 관련된 EDA는 위의 링크를 참조해주세요 :) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute '임대보증금'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-0b8a7de7f96f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m임대보증금\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m'-'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'임대보증금'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m임대보증금\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m'-'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'임대보증금'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'임대보증금'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'임대보증금'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'임대보증금'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'임대보증금'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5137\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5138\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5139\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5141\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute '임대보증금'"
     ]
    }
   ],
   "source": [
    "train.loc[train.임대보증금=='-', '임대보증금'] = np.nan\n",
    "test.loc[test.임대보증금=='-', '임대보증금'] = np.nan\n",
    "train['임대보증금'] = train['임대보증금'].astype(float)\n",
    "test['임대보증금'] = test['임대보증금'].astype(float)\n",
    "\n",
    "train.loc[train.임대료=='-', '임대료'] = np.nan\n",
    "test.loc[test.임대료=='-', '임대료'] = np.nan\n",
    "train['임대료'] = train['임대료'].astype(float)\n",
    "test['임대료'] = test['임대료'].astype(float)\n",
    "\n",
    "train[['임대보증금', '임대료']] = train[['임대보증금', '임대료']].fillna(0)\n",
    "test[['임대보증금', '임대료']] = test[['임대보증금', '임대료']].fillna(0)\n",
    "\n",
    "cols = ['도보 10분거리 내 지하철역 수(환승노선 수 반영)', '도보 10분거리 내 버스정류장 수']\n",
    "train[cols] = train[cols].fillna(0)\n",
    "test[cols] = test[cols].fillna(0)\n",
    "\n",
    "#### (3) 자격유형\n",
    "\n",
    "test.loc[test.단지코드.isin(['C2411']) & test.자격유형.isnull(), '자격유형'] = 'A'\n",
    "test.loc[test.단지코드.isin(['C2253']) & test.자격유형.isnull(), '자격유형'] = 'C'\n",
    "\n",
    "train = train.drop_duplicates()\n",
    "test = test.drop_duplicates()\n",
    "\n",
    "unique_cols = ['총세대수', '지역', '공가수', \n",
    "               '도보 10분거리 내 지하철역 수(환승노선 수 반영)',\n",
    "               '도보 10분거리 내 버스정류장 수',\n",
    "               '단지내주차면수', '등록차량수']\n",
    "train_agg = train.set_index('단지코드')[unique_cols].drop_duplicates()\n",
    "test_agg = test.set_index('단지코드')[[col for col in unique_cols if col!='등록차량수']].drop_duplicates()\n",
    "\n",
    "def reshape_cat_features(data, cast_col, value_col):\n",
    "    res = data.drop_duplicates(['단지코드', cast_col]).assign(counter=1).pivot(index='단지코드', columns=cast_col, values=value_col).fillna(0)\n",
    "    res.columns.name = None\n",
    "    res = res.rename(columns={col:cast_col+'_'+col for col in res.columns})\n",
    "    return res\n",
    "\n",
    "train.loc[train.공급유형.isin(['공공임대(5년)', '공공분양', '공공임대(10년)', '공공임대(분납)']), '공급유형'] = '공공임대(5년/10년/분납/분양)'\n",
    "test.loc[test.공급유형.isin(['공공임대(5년)', '공공분양', '공공임대(10년)', '공공임대(분납)']), '공급유형'] = '공공임대(5년/10년/분납/분양)'\n",
    "train.loc[train.공급유형.isin(['장기전세', '국민임대']), '공급유형'] = '국민임대/장기전세'\n",
    "test.loc[test.공급유형.isin(['장기전세', '국민임대']), '공급유형'] = '국민임대/장기전세'\n",
    "\n",
    "train.loc[train.자격유형.isin(['J', 'L', 'K', 'N', 'M', 'O']), '자격유형'] = '행복주택_공급대상'\n",
    "test.loc[test.자격유형.isin(['J', 'L', 'K', 'N', 'M', 'O']), '자격유형'] = '행복주택_공급대상'\n",
    "\n",
    "train.loc[train.자격유형.isin(['H', 'B', 'E', 'G']), '자격유형'] = '국민임대/장기전세_공급대상'\n",
    "test.loc[test.자격유형.isin(['H', 'B', 'E', 'G']), '자격유형'] = '국민임대/장기전세_공급대상'\n",
    "\n",
    "train.loc[train.자격유형.isin(['C', 'I', 'F']), '자격유형'] = '영구임대_공급대상'\n",
    "test.loc[test.자격유형.isin(['C', 'I', 'F']), '자격유형'] = '영구임대_공급대상'\n",
    "\n",
    "X_train = pd.concat([train_agg,\n",
    "                       reshape_cat_features(data=train, cast_col='임대건물구분', value_col='counter'),\n",
    "                       reshape_cat_features(data=train, cast_col='공급유형', value_col='counter'),\n",
    "                       reshape_cat_features(data=train, cast_col='자격유형', value_col='counter')], axis=1)\n",
    "\n",
    "X_test = pd.concat([test_agg,\n",
    "                       reshape_cat_features(data=test, cast_col='임대건물구분', value_col='counter'),\n",
    "                       reshape_cat_features(data=test, cast_col='공급유형', value_col='counter'),\n",
    "                       reshape_cat_features(data=test, cast_col='자격유형', value_col='counter')], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-2. Feature Engineering\n",
    "- 필요성?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head(3)\n",
    "\n",
    "# 1. 지역은 글자데이터이다.\n",
    "## 한글은 Catboost 이외에는 받아들일 수 없기  때문에, Encoding 과정이 필요하다.\n",
    "## 해결법  : 통계치를 반영한 Encoding과, One-Hot Encoding 모두 적용해준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.describe()\n",
    "\n",
    "# 2. 단위가 다르다.\n",
    "## 총 세대수, 공가수는 \"세대 수\"를, \"도보 ~~\"는 근처의 \"개수\"를, \"단지내주차면수\"는 \"면적\"을 의미하는 등 의미하는 바가 다르다.\n",
    "## 이 경우에는, Feature의 \"Scale\"을 동일하게 해주지 않으면 Machine Learning과정에서 가중치 학습에 있어서 오류가 있을 수 있다.\n",
    "## 해결법 : Robust Scailing을 적용해준다. (Good for outliers)\n",
    "\n",
    "# 3. 이상치가 보인다.\n",
    "## \"도보 10분 거리 내 버스정류장 수\"를 확인하면, 75%까지는 4이나, max는 20인 것을 확인할 수 있다.\n",
    "## \"도보 10분 거리 내 지하철역~`\"은 75%까지는 0이지만, max는 3인 것을 확인할 수 있다.\n",
    "## 이상치는 Linear Regression Model에서 상대적으로 큰 영향력을 끼친다.\n",
    "## 해결법 : 데이터를 살펴보고, 처리를 결정한다.\n",
    "\n",
    "# 4. 의미 없는 Feature도 확인되었다.\n",
    "## \"임대건물구분_아파트\"의 경우 모두가 1이다.\n",
    "## 해결법 : 단순 제거해준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop(columns = ['임대건물구분_아파트'])\n",
    "X_test = X_test.drop(columns = ['임대건물구분_아파트'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 필요성 - 3. 이상치가 보인다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot([train['도보 10분거리 내 버스정류장 수']])\n",
    "plt.show()\n",
    "\n",
    "# 20에 가까운 값들이 존재하지만, 따로 처리해주기에는 독립적으로 떨어진 분포가 아니기 때문에, 제거하지 않는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display('Train Data')\n",
    "display(X_train.groupby(['도보 10분거리 내 지하철역 수(환승노선 수 반영)'])['총세대수'].agg('count'))\n",
    "display('='*50)\n",
    "display('Test Data')\n",
    "display(X_test.groupby(['도보 10분거리 내 지하철역 수(환승노선 수 반영)'])['총세대수'].agg('count'))\n",
    "display('='*50)\n",
    "# 지하철 역 수가 3인 데이터는 제거한다.\n",
    "\n",
    "display('After Engineering')\n",
    "X_train = X_train[X_train['도보 10분거리 내 지하철역 수(환승노선 수 반영)'] != 3]\n",
    "display(X_train.groupby(['도보 10분거리 내 지하철역 수(환승노선 수 반영)'])['총세대수'].agg('count'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3-2-1. Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "encoding_features = ['지역', '도보 10분거리 내 지하철역 수(환승노선 수 반영)']\n",
    "for f in encoding_features:\n",
    "    mapping = X_train.groupby([f])['등록차량수'].agg(['mean','median','std'])\n",
    "    mapping_values = []\n",
    "    for l in X_train[f].values:\n",
    "        mapping_values.extend([mapping.loc[l].values])\n",
    "    bincount = pd.DataFrame(mapping_values, columns = [f+'_mean', f+'_median', f+'_std', ], index = X_train.index)\n",
    "    X_train = pd.concat([X_train,bincount], axis= 1).drop(columns = [f])\n",
    "\n",
    "    mapping_values = []\n",
    "    for l in X_test[f].values:\n",
    "        mapping_values.extend([mapping.loc[l].values])\n",
    "    bincount = pd.DataFrame(mapping_values, columns = [f+'_mean', f+'_median', f+'_std', ], index = X_test.index)\n",
    "    X_test = pd.concat([X_test,bincount], axis= 1).drop(columns = [f])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3-2-2. Scailing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scailing_features = ['총세대수',\n",
    "                     '공가수',\n",
    "                     '도보 10분거리 내 버스정류장 수',\n",
    "                     '단지내주차면수',\n",
    "                     '지역_mean', \n",
    "                     '지역_median',\n",
    "                     '지역_std', \n",
    "                     '도보 10분거리 내 지하철역 수(환승노선 수 반영)_mean',\n",
    "                   '도보 10분거리 내 지하철역 수(환승노선 수 반영)_median',\n",
    "                   '도보 10분거리 내 지하철역 수(환승노선 수 반영)_std'\n",
    "                    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2,5, figsize= (12,12))\n",
    "\n",
    "i = 0\n",
    "for f in scailing_features:\n",
    "    c = i % 5\n",
    "    r = i // 5\n",
    "    \n",
    "    axes[r,c].hist(x = f, bins =50, data = X_train)\n",
    "    i += 1\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# 지역은 이상치가 확인 => Robust Scailing\n",
    "# 도보 -> std 제거\n",
    "# 나머지는 Standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 도보 10분거리 std는 그림상 의미가 없기에 Drop\n",
    "X_train = X_train.iloc[:,:-1]\n",
    "X_test = X_test.iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 지역은  Scailing\n",
    "\n",
    "scaler = RobustScaler()\n",
    "loc_f = [    '지역_mean', \n",
    "             '지역_median',\n",
    "             '지역_std', ]\n",
    "X_train.loc[:, loc_f] = scaler.fit_transform(X_train[loc_f])\n",
    "X_test.loc[:, loc_f] = scaler.transform(X_test[loc_f])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 나머지 Scailing\n",
    "scailing_features = ['총세대수',\n",
    "                     '공가수',\n",
    "                     '도보 10분거리 내 버스정류장 수',\n",
    "                     '단지내주차면수',\n",
    "                     '도보 10분거리 내 지하철역 수(환승노선 수 반영)_mean',\n",
    "                       '도보 10분거리 내 지하철역 수(환승노선 수 반영)_median',\n",
    "                    ]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train.loc[:, scailing_features] = scaler.fit_transform(X_train[scailing_features])\n",
    "X_test.loc[:, scailing_features] = scaler.transform(X_test[scailing_features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Modeling with pycaret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = setup(train, \n",
    "            preprocess = False, # True로 설정되면, 자체적인 Feature Engineering을 추가로 진행해 Predict가 불가능해진다.\n",
    "            train_size = 0.999,  # 우리는 전체 데이터를 학습해 test를 예측하는게 목표이기 때문에, 0.999로 설정한다.\n",
    "            target = 'target', # 목표 변수는 등록 차량 수 이다.\n",
    "            silent = True, # 엔터를 누르기 귀찮다. 궁금하면 풀어보세요\n",
    "            use_gpu = False, # GPU가 있으면 사용하세요 (Cat BOost 속도 향상)\n",
    "            numeric_features=list(train.drop(columns = ['target']).columns), # 모든 변수가 숫자로써의 의미가 있다.\n",
    "            session_id = 2021,\n",
    "            fold_shuffle = True\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Top5의 모델 선택"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top5 = compare_models(n_select = 5, sort = 'MAE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Top5 Model Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "for m in top5:\n",
    "    models.append(tune_model(m, \n",
    "                             optimize = 'MAE', \n",
    "                             choose_better = True,\n",
    "                            n_iter = 30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voting = blend_models(models, optimize = 'MAE')\n",
    "voting = tune_model(voting, \n",
    "                 optimize = 'MAE', \n",
    "                 choose_better = True,\n",
    "                 n_iter = 30)\n",
    "\n",
    "voting = finalize_model(voting)\n",
    "sample = pd.read_csv('data/sample_submission.csv')\n",
    "layer1_pred = voting.predict(test)\n",
    "sample['num'] = layer1_pred\n",
    "sample.to_csv('sub/pycaret.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = pd.read_csv('data/sample_submission.csv')\n",
    "layer1_pred = voting.predict(test)\n",
    "sample['num'] = layer1_pred\n",
    "sample.to_csv('sub/pycaret0725.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling with Gradient Boosting Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Setting Data For Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop(columns = ['target'])\n",
    "y = train['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Hyper params Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial: Trial) -> float:\n",
    "    params_cat = {\n",
    "        \"random_state\": 42,\n",
    "        \"learning_rate\": 0.05,\n",
    "        \"n_estimators\": 10000,\n",
    "        \"verbose\" : 1,\n",
    "        \"objective\" : \"MAE\",\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 1, 16),\n",
    "        \"colsample_bylevel\": trial.suggest_float(\"colsample_bylevel\", 0.8, 1.0),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.3, 1.0),\n",
    "        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 5, 100),\n",
    "        \"max_bin\": trial.suggest_int(\"max_bin\", 200, 500),\n",
    "    }\n",
    "    \n",
    "    X_tr, X_val, y_tr, y_val = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "    model = CatBoostRegressor(**params_cat)\n",
    "    model.fit(\n",
    "        X_tr,\n",
    "        y_tr,\n",
    "        eval_set=[(X_tr, y_tr), (X_val, y_val)],\n",
    "        early_stopping_rounds=10,\n",
    "        verbose=False,\n",
    "    )\n",
    "\n",
    "    cat_pred = model.predict(X_val)\n",
    "    log_score = mean_absolute_error(y_val, cat_pred)\n",
    "    \n",
    "    return log_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = TPESampler(seed=42)\n",
    "study = optuna.create_study(\n",
    "    study_name=\"cat_opt\",\n",
    "    direction=\"minimize\",\n",
    "    sampler=sampler,\n",
    ")\n",
    "study.optimize(objective, n_trials=10)\n",
    "print(\"Best Score:\", study.best_value)\n",
    "print(\"Best trial:\", study.best_trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_p = study.best_trial.params\n",
    "cat = CatBoostRegressor(**cat_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- StratifiedK-Fold for Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_cat = pd.cut(y, 10, labels=range(10))\n",
    "skf = StratifiedKFold(5)\n",
    "\n",
    "preds = []\n",
    "for tr_id, val_id in skf.split(X, y_cat) : \n",
    "    X_tr = X.iloc[tr_id]\n",
    "    y_tr = y.iloc[tr_id]\n",
    "    \n",
    "    cat.fit(X_tr, y_tr, verbose = 0)\n",
    "    \n",
    "    pred = cat.predict(test)\n",
    "    preds.append(pred)\n",
    "cat_pred = np.mean(preds, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = pd.read_csv('data/sample_submission.csv')\n",
    "sample['num'] = cat_pred\n",
    "sample.to_csv('sub/cat0725.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
